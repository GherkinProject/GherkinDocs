\documentclass{report}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{lmodern}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathrsfs}
\usepackage{float}
\usepackage{geometry}
\geometry{scale=0.8, nohead}

\author{Gautier \bsc{Dakin}, Nicolas \bsc{Ehrhardt}}
\title{Projet Gherkin}

\begin{document}
\maketitle

\tableofcontents


\chapter{L'interface graphique}
\section{Orientation du projet}
Comme sus-mentionné nous avons basé notre interface sur celle du lecteur audio par défaut (type Rhythmbox, de sorte à ne pas perturber les habitudes de l'utilisateur). Mais un constat s'impose : Aujourd'hui, les écran 16/10 voire 16/9 sont légions et majoritaires ; Ubuntu, à travers unity, à décidé de tirer parti de ce nouvel état de fait pour proposer un menu latéral. Les arguments sont : gain de place, minimalisme. Le principal problème étant que ce menu empiète parfois sur les boutons des applications en plein écran lorsque celui-ci se dévoile.

Pour répondre à cette problèmatique, nous proposons un menu à droite de notre application. Optimisant ainsi la place, et évitant cette gène.

\section{Développement}
La librairie PyQt4 sur laquelle se base le lecteur nous a permis de développer rapidemment cette interface. Le développement de l'interface s'est fait en trois temps :
\begin{enumerate}
\item On crée dans un premier temps une première interface graphique grâce à QtDesigner. Cette application permet d'avoir une vision en WYSIWYG (\emph{What you see is what you get}) de l'interface, et donc d'éviter les erreurs de goûts et de mauvais placement.
\item On modifie légèrement le code généré par QtDesigner pour rajouter quelques fonctionnalités. (Ex : Gestion des îcones)
\item On sépare le fichier en deux .py. Un premier contient le code légèrement modifié obtenu via QtDesigner. Le second va gérer toutes les modifications de l'interface graphique, ainsi que la gestion des signaux et slots de Qt. (Ex : l'update de la barre de progression, lié le PlayButton à la fonction play(),... )
\end{enumerate}

\begin{figure}[h]
\centering
\includegraphics[scale=.3]{interface.png}
\caption{Interface graphique du lecteur.}
\end{figure}


Nous avons, en outre, rajouté plusieurs fenêtres supplémentaires. Une première fenêtre permet de pouvoir sélectionner l'endroit où se trouve la musique (DDE, Dossier Musique, ...) afin que l'utilisateur puisse mettre à jour sa base de données sans avoir à passer par le mode console. Une seconde fenêtre a été créée et permet à l'utilisateur de pouvoir voir l'état de la playlist en cours de lecture, de la modifier si besoin en ôtant ou en rajoutant des éléments. Enfin une dernière fenêtre permet de rentrer l'adresse IPv4 d'un serveur pour pouvoir directement écouter la musique depuis le serveur, à condition, évidemment, que l'adresse IP rentrée soit valide.

\chapter{L'intelligence}
\section{L'idée du côté utilisateur}

L'idée de l'intelligence est simple en elle-même. Elle a pour but de mettre des probabilités sur le passage entre deux chansons. Exemple : Vous êtes actuellement entrain d'écouter la "Sonate au Clair de Lune". Théoriquement, la probabilité d'avoir envie d'entendre/écouter "Highway to Hell" après la "Sonate au Clair de Lune" est extrêmement faible (sauf si cela est dans vos habitudes).
Si, au contraire, après la sonate de Beethoven, l'utilisateur a tendance à écouter le "Requiem" de Mozart, alors la probabilité de passage entre ces deux chansons sera d'autant plus grande.

Cette vision de passage d'une chanson à l'autre entre exactement dans le cadre théorique des chaînes de Markov où l'on a une matrice P tel que $P(x,y)$ représente la probabilité de passage de l'état x à l'état y.

\subsection{Développement}

On a donc l'idée de représenter les transitions entre deux pistes audio par une chaine de Markov. Reste à savoir comment l'implémenter. Imaginons une bibliothèque moyenne sur un ordinateur. On tourne autour de $4000 -- 5000$ pistes audio. Gérer en permanence une telle matrice est extrêmement lourd, or on recherche en premier la rapidité d'exécution. On développe donc comme suit :

\begin{itemize}
\item
On crée un dictionnaire de nom markov, tel que $markov[i][j]$ renvoie la probabilité de passage de $i$ à $j$ si elle existe.
\item
On pondère ces probabilités par un nombre dépendant uniquement de i. Ce choix implique qu'on considère qu'à un temps très élevé, on a théoriquement convergence vers la playlist idéale pour l'utilisateur. Cela ne signifie pas pour autant que la playlist devient déterministe. On a juste théoriquement élagué les probabilités très faibles pour ne laisser plus que les probabilités plus importantes. On a donc en théorie une convergence vers un arbre de probabilité plus ou
moins stable par utilisation de Gherkin.
\item
Selon certains critères, on décide d'incrémenter ou de décrémenter la probabilité, en gardant le caractère stochastique de markov. On incrémente ainsi la probabilité lorsque l'on réalise l'écoute entière d'un morceau, on incrémente la probabilité entre le morceau précédent et ce morceau. Lorsque l'utilisateur décide de passer une chanson, on abaisse la probabilité de passage entre le morceau précédent et le morceau qui vient d'être sauté. Enfin, on décide
d'incrémenter la probabilité lorsqu'un morceau est double cliqué, ce qui peut permettre à l'utilisateur de configurer en quelques instants ces playlists.
\item
Régulièrement, on enregistre le dictionnaire markov sur le disque dur. Enfin d'éviter de revenir au cas de la matrice, les probabilités trop faibles ($ < \epsilon$) sont élaguées c'est-à-dire qu'elles sont suppriméees et rajoutées équiprobablement sur les autres clefs du dictionnaire. Cet élagage permet de réduire le nombre de clefs du dictionnaire et donc de garantir une taille plus faible.
\end{itemize}


\section{L'idée du côté serveur}

Du côté utilisateur, on ne se focalise que ses préférences personnelles. Du côté serveur, on ne peut se permettre de faire cela. Certes, on pourrait considérer la moyenne des préférences des utilisateurs, mais ce ne serait qu'un vulgaire plagiat de ce qu'un grand nombre de lecteurs audio sur Internet fait.

Nous avons donc fait le choix de faire du machine-learning sur les bases de données, c'est-à-dire essayer par un algorithme de machine-learning de classifier les chansons, et des les isoler en sous-groupes pertinents afin de faciliter le stockage et permettre à l'utilisateur une utilisation intéressante.

Pour se faire, nous avons besoin de pouvoir créer des données à classifier par un quelconque algorithme. On utilise pour faire cela la bibliothèque Yaafe. Cette bibliothèque permet d'extraire 22 constantes propres à chaque chanson qui détermine son rythme, son timbre et ses sonorités. On obtient donc après traitement des données, une immense matrice de 22 colonnes et d'autant de lignes que de chansons dans la base de données.

Il faut désormais traiter cette matrice. Les algorithmes qui nous apparaissent comme pertinents dans le cadre d'une classification d'oeuvres musicales sont les algorithmes de clustering.

Le clustering consiste à créer des sous-groupes de données au sein d'un immense jeu de données, et donc d'attribuer ici à chaque morceau de musique, un cluster ou un groupe d'appartenance. L'intérêt du clustering est qu'il nous permet donc de dire qu'un morceau appartient à tel sous groupe et donc qu'à la fin de la lecture de ce morceau, la probabilité est assez forte de rester au sein de ce groupe, puisqu'ils sont en théorie assez proche musicalement parlant, il existe ensuite une probabilité, plus faible, de quitter ce cluster et d'aller en rejoindre un autre. Plus ce second cluster sera proche du premier en terme de distance "musicale" toujours, plus la probabilité sera proche.


Les algorithmes retenus sont issus d'une bibliothèque du logiciel $R$ (la librairie cluster). Ils sont au nombre de 3 : k-means, pam et fanny.

\subsection{K-means}

L'algorithme K-means consiste à dire qu'un morceau de musique appartient à un groupe noté $\mathfrak{G}$ si et seulement si la majorité de ses k-plus proches voisins sont aussi dans le groupe $G$. C'est donc un algorithme basique (presque naïf) qui a l'immense avantage d'être rapide comparé aux deux autres algorithmes, bien que l'algorithme sont moins stables que les deux autres.

Concrètement en projetant le résultat obtenu dans les deux premières dimensions, on obtient un graphique de ce type. Chaque rond y représente un morceau de musique, chaque étoile un cluster qui donne sa couleur à son groupe.


\begin{figure}[H]
\centering
\subfloat[Bibliothèque en 2D]{\includegraphics[width=8cm]{KMEANSBiblio2D.png}}
\subfloat[PCA 3D \#1]{\includegraphics[width=8cm]{KMEANS-PCA-3D1.png}}\\
\subfloat[PCA 3D \#2]{\includegraphics[width=8cm]{KMEANS-PCA-3D2.png}}
\subfloat[PCA 3D \#3]{\includegraphics[width=8cm]{KMEANS-PCA-3D3.png}}
\caption{Projection des données en trois dimensiosn après clustering}
\end{figure}

\subsection{Fanny (Fuzzy Analysis clustering)}

L'algorithme Fanny ne classifie pas directement un morceau comme appartenant à un groupe $G$ mais en donnant à la place la probabilité pour un morceau d'appartenir à tel ou tel groupe (ou cluster). On peut ensuite apprendre le cluster en prenant le cluster qui maximise cette probabilité. L'avantage de ces probabilités est qu'elles permettent de voir la pertinence de l'appartenance d'un morceau à tel ou tel cluster, et semble être un peu moins sélectif que le cas normal.

\subsection{Pam}

Bla bla sur les médoides


\subsection{Chaîne de Markov}

En sortie de ce clustering, on souhait obtenir une nouvelle chaîne de Markov, telle que $markovS[i][j]$ représente la probabilité de passage du morceau $i$ au groupe de musique $j$. Il suffira ensuite de sélectionner une musique aléatoirement ou selon les préférences de l'utilisateur dans ce groupe de musique et de la jouer. Dans le cas où l'on utiliserait en sortie le custering de fanny, on aurait directement cette chaîne de Markov. Sinon, pour les deux autres algorithmes, il suffirait de la construire, en se basant sur la distance entre les clusters (qu'elle soit calculée entre les deux plus proches éléments, les deux plus éloignés ou en moyenne).


\chapter{Architecture en client/serveur}

\begin{figure}[ht]
\centering
\includegraphics[scale=.8]{clientServeur.png}
\caption{Relation client-serveur}
\end{figure}

L'architecture client-serveur est très souvent utilisée en informatique pour permettre de distinguer différentes parties d'un logiciel. Dans notre cas, nous avons identifié trois parties indépendantes pour le lecteur Gherkin. La première étant une couche que l'on pourrait appeler de bas niveau, la base audio. Celle-ci s'occupe de faire le lien entre Gherkin et la librairie audio du système hôte. Elle fournit alors une base solide et constante pour bâtir le coeur de notre logiciel : l'intelligence artificielle.

Cet ensemble forme le serveur Gherkin, celui-ci est complètement indépendant du reste du logiciel. Et ses échanges avec ses clients se font au moyen de commandes réseau (via la librairie XMLRPC). Ceci permet donc de controler le serveur depuis une machine distante.

Le client quant à lui possède deux fonctions. La première est de mettre en forme les informations envoyées par le serveur, par exemple, afficher la playlist, indiquer la position dans la chanson. La seconde, transmettre les actions effectuées par l'utilisateur au serveur qui prendra alors une décision, par exemple, passer en mode lecture aléatoire, passer la chanson, etc...

\chapter{Langages et bibliothèques utilisés}

\section{Langages de programmation}
\subsection{Python}

Python est un langage de programmation multi-paradigme. Il favorise la programmation impérative structurée, et orientée objet. Il est doté d'un typage dynamique fort, d'une gestion automatique de la mémoire par ramasse-miettes et d'un système de gestion d'exceptions ; il est ainsi similaire à Perl, Ruby, Scheme, Smalltalk et Tcl. (Source : \emph{Wikipedia})


Il est utilisé très majoritairement dans le code de Gherkin, puisque c'est lui qui réalise toutes les interfaces entre les différentes librairies. Un des points faibles de Python est qu'étant un langage interprété, il est plus lent qu'un langage compilé, mais sa syntaxe et sa souplesse rend la programmation bien plus agréable et plus simple à relire.


\subsection{Bash}
Bash, acronyme de Bourne-again shell, est le shell du projet GNU. Son nom est un jeu de mots sur le nom du shell historique d'Unix, le Bourne shell. 

Basé sur le Bourne shell, Bash lui apporte de nombreuses améliorations, provenant notamment du Korn shell et du C shell. Bash est un logiciel libre publié sous GNU GPL. Il est l'interprète par défaut sur de nombreux Unix libres, notamment sur les systèmes GNU/Linux. C'est aussi le shell par défaut de Mac OS X et il a été porté sous Windows par le projet Cygwin. (source : \emph{Wikipedia})

Ce langage est utilisé afin de réaliser des automatismes d'exécution. Expliquons-nous. Pour pouvoir utiliser Yaafe convenablement, sans avoir 6 Go de données temporaires, on utilise un script en Bash qui permet de traiter les données pour un morceau de musique, de les stocker puis de supprimer directement les fichiers temporaires, ce qui permet d'éviter les crashs parce que trop de mémoires dures ont été utilisées.

\subsection{XML}

Le XML (Extensible Markup Language, « langage de balisage extensible ») est un langage informatique de balisage générique qui dérive du SGML. Cette syntaxe est dite extensible car elle permet de définir différents espaces de noms, c'est-à-dire des langages avec chacun leur vocabulaire et leur grammaire, comme XHTML, XSLT, RSS… Elle est reconnaissable par son usage des chevrons (< >) encadrant les balises. L'objectif initial est de faciliter l'échange automatisé de contenus complexes (arbres, texte riche…) entre systèmes d'informations hétérogènes (interopérabilité). Avec ses outils et langages associés une application XML respecte généralement certains principes :
\begin{itemize}
\item    la structure d'un document XML est définie et validable par un schéma,
\item    un document XML est entièrement transformable dans un autre document XML.
\end{itemize}
(source : \emph{Wikipedia})


Le langage XML est utilisé pour le stockage de la base de données audio (db.xml). 

\subsection{R}

R est un langage de programmation et un environnement mathématique utilisés pour le traitement de données et l'analyse statistique. C'est un projet GNU fondé sur le langage S et sur l'environnement développé dans les laboratoires Bell par John Chambers et ses collègues. Depuis plusieurs années, deux nouvelles versions apparaissent au printemps et à l'automne. R dispose de nombreuses fonctions graphiques.

R est considéré par ses créateurs comme étant une exécution de S, avec la sémantique dérivée du langage Scheme. R est un logiciel libre distribué selon les termes de la licence GNU GPL et est disponible sous GNU/Linux, FreeBSD, NetBSD, OpenBSD, Mac OS X et Windows. R représente aujourd'hui l'un des objectifs techniques majeurs de la communauté hacker GNU. (Source :\emph{Wikipedia})



R est utilisé afin de réaliser l'apprentissage automatique sur les données générées par Yaafe. Il permet en outre l'affichage en 3D des données, la couleur dépendant du cluster auquel ils ont été attribués.

\section{Bibliothèques}

\subsection{GStreamer}

GStreamer est une bibliothèque logicielle de gestion globale du son et de l'image (appelée aussi framework multimédia) écrite en C pour systèmes UNIX (GNU/Linux, BSD, etc.) initialement développé pour GNU/Linux. Il a dans un premier temps (sa première version publique date du 31 octobre 1999) été adopté par le projet GNOME dont il est devenu un pilier (Totem, Rhythmbox et PiTiVi, par exemple, en tirent largement partie), puis a continué son évolution et de plus en plus d'applications l'utilisent.

(source : \emph{Wikipédia})

Pour des soucis de portabilité, gstreamer ne fonctionne actuellement que sous plate-forme UNIX. Néanmoins, il devrait progressivement pouvoir être adaptable et utilisable sous Windows.

\subsection{Yaafe}

Yaafe est une bibliothèque créée au sein de Telecom Paristech et qui permet l'extraction de caractéristiques spécifiques sonores à un morceau de musique. Nous utilisons cette bibliothèque afin de récolter des données sur l'ensemble des morceaux de musique de la bibliothèque afin de réaliser ensuite de l'apprentissage automatique dessus.

Yaafe permet :
\begin{itemize}
\item    de récolter une grande variété de caractéristiques spécifiques audio, ainsi que des transformations et des intégrations sur une fenêtre temporelle. 
\item    permet de lire le format WAV, OGG, MP3.
\item    permet d'écrire en sortie des fichiers CSV ou HDF5 regroupant les données calculées.
\item    Interface en Python ou en Matlab.
\end{itemize}


\subsection{XMLRPC}
XML-RPC est un protocole RPC (Remote procedure call), une spécification simple et un ensemble de codes qui permettent à des processus s'exécutant dans des environnements différents de faire des appels de méthodes à travers un réseau.

XML-RPC permet d'appeler une fonction sur un serveur distant à partir de n'importe quel système (Windows, Mac OS X, GNU/Linux) et avec n'importe quel langage de programmation. Le serveur est lui même sur n'importe quel système et est programmé dans n'importe quel langage.

Cela permet de fournir un Service web utilisable par tout le monde sans restriction de système ou de langage.

Les processus d'invocation à distance utilisent le protocole HTTP pour le transfert des données et la norme XML pour la structuration des données.

XML-RPC est conçu pour permettre à des structures de données complexes d'être transmises, exécutées et renvoyées très facilement.
(source : \emph{Wikipédia})


\subsection{ConfigParser}




\chapter{Historique de Gherkin}


\chapter{Les grandes lignes du code}
% DOXYGENE



\chapter*{Bibliographie}

YAAFE, an Easy to Use and Efficient Audio Feature Extraction Software, B.Mathieu, S.Essid, T.Fillon, J.Prado, G.Richard, proceedings of the 11th ISMIR conference, Utrecht, Netherlands, 2010.



\end{document}
